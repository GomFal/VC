{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Python>=3.10 is required, but Python==3.9.20 is currently installed \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio de nombre de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Número actual de imágenes\n",
    "imagenes_actuales = 125\n",
    "\n",
    "# Ruta de la carpeta original que contiene las imágenes\n",
    "ruta_original = \"imagenes\"\n",
    "\n",
    "# Nombre de la nueva carpeta donde se guardarán las imágenes renombradas\n",
    "nueva_carpeta = \"Dataset/\"\n",
    "\n",
    "# Asegurarse de que la nueva carpeta existe o se crea\n",
    "if not os.path.exists(nueva_carpeta):\n",
    "    os.makedirs(nueva_carpeta)\n",
    "\n",
    "# Recorrer las imágenes en la carpeta original\n",
    "for i, nombre_archivo in enumerate(os.listdir(ruta_original)):\n",
    "    # Verificar si el archivo es una imagen (puedes añadir más extensiones si lo necesitas)\n",
    "    if nombre_archivo.endswith(('.jpg')):\n",
    "        # Definir el nuevo nombre para la imagen (ejemplo: imagen_1.jpg)\n",
    "        nuevo_nombre = f\"imagen_{i+1+imagenes_actuales}.jpg\"\n",
    "\n",
    "        # Ruta completa del archivo original\n",
    "        ruta_original_completa = os.path.join(ruta_original, nombre_archivo)\n",
    "\n",
    "        # Ruta completa del nuevo archivo\n",
    "        ruta_nueva_completa = os.path.join(nueva_carpeta, nuevo_nombre)\n",
    "\n",
    "        # Copiar y renombrar la imagen a la nueva carpeta\n",
    "        shutil.copy(ruta_original_completa, ruta_nueva_completa)\n",
    "\n",
    "print(\"Proceso completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de los directorios train, val y test para añadir imagenes nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los directorios de train, test y val han sido limpiados.\n"
     ]
    }
   ],
   "source": [
    "# Función para limpiar los directorios de imágenes y etiquetas\n",
    "def limpiar_directorios(carpeta_destino):\n",
    "    # Subcarpetas para los conjuntos de datos\n",
    "    subcarpetas = ['train', 'test', 'val']\n",
    "    \n",
    "    # Tipos de archivo que queremos eliminar\n",
    "    extensiones = ['.jpg', '.png', '.txt']  # Añade aquí otras extensiones de imagen si es necesario\n",
    "    \n",
    "    for subcarpeta in subcarpetas:\n",
    "        carpeta_imagenes = os.path.join(carpeta_destino, subcarpeta, \"images\")\n",
    "        carpeta_labels = os.path.join(carpeta_destino, subcarpeta, \"labels\")\n",
    "        \n",
    "        # Eliminar archivos en la carpeta de imágenes\n",
    "        if os.path.exists(carpeta_imagenes):\n",
    "            for archivo in os.listdir(carpeta_imagenes):\n",
    "                if any(archivo.endswith(ext) for ext in extensiones):\n",
    "                    os.remove(os.path.join(carpeta_imagenes, archivo))\n",
    "        \n",
    "        # Eliminar archivos en la carpeta de etiquetas\n",
    "        if os.path.exists(carpeta_labels):\n",
    "            for archivo in os.listdir(carpeta_labels):\n",
    "                if archivo.endswith('.txt'):\n",
    "                    os.remove(os.path.join(carpeta_labels, archivo))\n",
    "    \n",
    "    print(\"Los directorios de train, test y val han sido limpiados.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "carpeta_destino = \"VC_P4-NUM_PLATES\"  # Ruta a la carpeta principal\n",
    "limpiar_directorios(carpeta_destino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución de las imágenes entre train (70%), test (20%) y val (10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las imágenes y archivos .txt de anotaciones han sido divididos en train, test y val.\n"
     ]
    }
   ],
   "source": [
    "# Definir las clases y el ID de la clase \"matricula\"\n",
    "clases = [\"matricula\"]\n",
    "\n",
    "# Función para convertir al formato YOLO y escribir en el archivo .txt\n",
    "def convertir_a_yolo(class_id, x_min, y_min, x_max, y_max, imagen_ancho, imagen_alto, archivo_txt):\n",
    "    # Calcular coordenadas y tamaño del bounding box normalizado\n",
    "    x_center = ((x_min + x_max) / 2) / imagen_ancho\n",
    "    y_center = ((y_min + y_max) / 2) / imagen_alto\n",
    "    width = (x_max - x_min) / imagen_ancho\n",
    "    height = (y_max - y_min) / imagen_alto\n",
    "\n",
    "    # Escribir en el archivo .txt en formato YOLO\n",
    "    archivo_txt.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Ruta de la carpeta original que contiene las imágenes y JSON\n",
    "carpeta_original = \"Dataset\"\n",
    "\n",
    "# Carpeta de destino principal\n",
    "carpeta_destino = \"VC_P4-NUM_PLATES\"\n",
    "\n",
    "# Subcarpetas dentro de cada subconjunto\n",
    "subcarpetas = ['train', 'test', 'val']\n",
    "carpeta_images = {subcarpeta: os.path.join(carpeta_destino, subcarpeta, \"images\") for subcarpeta in subcarpetas}\n",
    "carpeta_labels = {subcarpeta: os.path.join(carpeta_destino, subcarpeta, \"labels\") for subcarpeta in subcarpetas}\n",
    "\n",
    "# Asegurarse de que las carpetas de destino existen o se crean\n",
    "for subcarpeta in subcarpetas:\n",
    "    os.makedirs(carpeta_images[subcarpeta], exist_ok=True)\n",
    "    os.makedirs(carpeta_labels[subcarpeta], exist_ok=True)\n",
    "\n",
    "# Obtener todas las imágenes de la carpeta original\n",
    "imagenes = [f for f in os.listdir(carpeta_original) if f.endswith('.jpg')]\n",
    "\n",
    "# Mezclar las imágenes de forma aleatoria\n",
    "random.shuffle(imagenes)\n",
    "\n",
    "# Calcular cuántas imágenes irán en cada subconjunto\n",
    "total_imagenes = len(imagenes)\n",
    "train_size = int(0.7 * total_imagenes)\n",
    "test_size = int(0.2 * total_imagenes)\n",
    "val_size = total_imagenes - train_size - test_size  # Lo que queda es para val\n",
    "\n",
    "# Dividir las imágenes en tres subconjuntos\n",
    "train_imagenes = imagenes[:train_size]\n",
    "test_imagenes = imagenes[train_size:train_size + test_size]\n",
    "val_imagenes = imagenes[train_size + test_size:]\n",
    "\n",
    "# Función para copiar imágenes a las carpetas 'images' y crear archivos .txt con anotaciones en 'labels'\n",
    "def copiar_imagenes_con_anotaciones(imagenes, carpeta_imagenes, carpeta_labels):\n",
    "    for imagen in imagenes:\n",
    "        # Copiar la imagen a la subcarpeta \"images\"\n",
    "        ruta_origen_imagen = os.path.join(carpeta_original, imagen)\n",
    "        ruta_destino_imagen = os.path.join(carpeta_imagenes, imagen)\n",
    "        shutil.copy(ruta_origen_imagen, ruta_destino_imagen)\n",
    "\n",
    "        # Generar la ruta del archivo JSON correspondiente\n",
    "        nombre_sin_extension = os.path.splitext(imagen)[0]  # Nombre sin extensión\n",
    "        archivo_json = f\"{nombre_sin_extension}.json\"\n",
    "        ruta_origen_json = os.path.join(carpeta_original, archivo_json)\n",
    "\n",
    "        # Crear el archivo .txt en la carpeta \"labels\" y convertir el JSON a formato YOLO, si existe el JSON\n",
    "        ruta_txt = os.path.join(carpeta_labels, f\"{nombre_sin_extension}.txt\")\n",
    "        if os.path.exists(ruta_origen_json):\n",
    "            with open(ruta_txt, 'w') as archivo_txt, open(ruta_origen_json, 'r') as json_file:\n",
    "                datos = json.load(json_file)\n",
    "\n",
    "                # Abrir la imagen para obtener sus dimensiones\n",
    "                with Image.open(ruta_destino_imagen) as img:\n",
    "                    imagen_ancho, imagen_alto = img.size\n",
    "\n",
    "                # Recorrer los objetos anotados en el JSON y escribir en formato YOLO\n",
    "                for forma in datos['shapes']:\n",
    "                    if forma['label'] == 'matricula' and forma['shape_type'] == 'rectangle':\n",
    "                        puntos = forma['points']\n",
    "                        x_min = min(p[0] for p in puntos)\n",
    "                        y_min = min(p[1] for p in puntos)\n",
    "                        x_max = max(p[0] for p in puntos)\n",
    "                        y_max = max(p[1] for p in puntos)\n",
    "\n",
    "                        # Llamar a la función que convierte al formato YOLO y escribe en el archivo .txt\n",
    "                        class_id = clases.index('matricula')\n",
    "                        convertir_a_yolo(class_id, x_min, y_min, x_max, y_max, imagen_ancho, imagen_alto, archivo_txt)\n",
    "\n",
    "# Copiar las imágenes y crear los archivos .txt en las carpetas correspondientes\n",
    "copiar_imagenes_con_anotaciones(train_imagenes, carpeta_images['train'], carpeta_labels['train'])\n",
    "copiar_imagenes_con_anotaciones(test_imagenes, carpeta_images['test'], carpeta_labels['test'])\n",
    "copiar_imagenes_con_anotaciones(val_imagenes, carpeta_images['val'], carpeta_labels['val'])\n",
    "\n",
    "print(\"Las imágenes y archivos .txt de anotaciones han sido divididos en train, test y val.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo entrenado\n",
    "model = YOLO('runs/detect/train2/weights/best.pt')\n",
    "\n",
    "# Ruta del video de entrada\n",
    "filename = \"C0142.MP4\"\n",
    "\n",
    "# Abrir el archivo de video\n",
    "cap = cv2.VideoCapture(filename)\n",
    "\n",
    "# Obtener información sobre el video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Crear la ruta de salida para el video procesado\n",
    "output_filename = 'video_con_detecciones_2.mp4'\n",
    "output_path = os.path.join(os.getcwd(), output_filename)\n",
    "\n",
    "# Crear un VideoWriter para guardar el video con detecciones\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# Procesar el video frame a frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Si no hay más frames, salir del bucle\n",
    "\n",
    "    # Realizar detecciones en el frame actual\n",
    "    results = model(frame)\n",
    "\n",
    "    # Obtener el frame anotado con las detecciones\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Guardar el frame anotado en el archivo de video de salida\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "# Liberar los recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Video guardado en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrgable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "from yolov5 import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import easyocr  # Biblioteca OCR para reconocimiento de texto en matrículas\n",
    "\n",
    "# Inicializa el modelo de detección de objetos, OCR y seguimiento\n",
    "yolo_model = YOLO(\"yolov5s.pt\")\n",
    "tracker = DeepSort(max_age=30, n_init=3)\n",
    "ocr_reader = easyocr.Reader(['en'])  # Especifica el idioma que se va a usar para el OCR\n",
    "\n",
    "# Inicializa el video de entrada y salida\n",
    "video_input = cv2.VideoCapture(\"input_video.mp4\")\n",
    "video_output = cv2.VideoWriter(\"output_video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30, (int(video_input.get(3)), int(video_input.get(4))))\n",
    "\n",
    "# CSV donde se almacenará la información\n",
    "csv_data = []\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "while video_input.isOpened():\n",
    "    ret, frame = video_input.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detecta objetos en el fotograma\n",
    "    detections = yolo_model(frame)\n",
    "    \n",
    "    # Almacena las detecciones para DeepSort\n",
    "    bboxes = []\n",
    "    for det in detections:\n",
    "        if det['class'] in ['person', 'car']:  # Filtra las clases de interés\n",
    "            bboxes.append([det['x1'], det['y1'], det['x2'], det['y2'], det['confidence'], det['class']])\n",
    "\n",
    "    # Aplica el seguimiento\n",
    "    tracked_objects = tracker.update_tracks(bboxes, frame=frame)\n",
    "\n",
    "    # Dibuja las detecciones y seguimiento en el frame\n",
    "    for obj in tracked_objects:\n",
    "        if not obj.is_confirmed():\n",
    "            continue\n",
    "        track_id = obj.track_id\n",
    "        bbox = obj.to_tlbr()  # Bounding box\n",
    "        class_name = obj.get_class()  # Clases\n",
    "\n",
    "        # Si el objeto es un vehículo, intenta detectar la matrícula\n",
    "        matricula_text = \"\"\n",
    "        matricula_confianza = 0\n",
    "        matricula_bbox = [None, None, None, None]\n",
    "\n",
    "        if class_name == 'car':\n",
    "            # Recortar la región de la matrícula y aplicar OCR\n",
    "            vehicle_crop = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "            ocr_results = ocr_reader.readtext(vehicle_crop, detail=1, min_size=30)  # Cambia `min_size` según el tamaño de la matrícula\n",
    "\n",
    "            # Procesar resultados OCR\n",
    "            for (bbox_ocr, text, conf) in ocr_results:\n",
    "                if conf > matricula_confianza:  # Seleccionar el resultado OCR con mayor confianza\n",
    "                    matricula_text = text\n",
    "                    matricula_confianza = conf\n",
    "                    matricula_bbox = [bbox_ocr[0][0] + int(bbox[0]), bbox_ocr[0][1] + int(bbox[1]), \n",
    "                                      bbox_ocr[2][0] + int(bbox[0]), bbox_ocr[2][1] + int(bbox[1])]\n",
    "        \n",
    "        # Agrega la entrada al CSV\n",
    "        csv_data.append([frame_number, class_name, obj.confidence, track_id, *bbox, matricula_text, matricula_confianza, *matricula_bbox])\n",
    "\n",
    "        # Dibuja la caja y el ID\n",
    "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {track_id} {class_name}\", (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Dibuja la matrícula detectada\n",
    "        if matricula_text:\n",
    "            cv2.putText(frame, matricula_text, (int(matricula_bbox[0]), int(matricula_bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "            cv2.rectangle(frame, (int(matricula_bbox[0]), int(matricula_bbox[1])), (int(matricula_bbox[2]), int(matricula_bbox[3])), (0, 255, 255), 2)\n",
    "\n",
    "    # Guarda el frame anotado en el video de salida\n",
    "    video_output.write(frame)\n",
    "    frame_number += 1\n",
    "\n",
    "# Guarda el CSV\n",
    "df = pd.DataFrame(csv_data, columns=['fotograma', 'tipo_objeto', 'confianza', 'identificador_tracking', 'x1', 'y1', 'x2', 'y2', 'matrícula_en_su_caso', 'confianza_matricula', 'mx1', 'my1', 'mx2', 'my2'])\n",
    "df.to_csv(\"output_data.csv\", index=False)\n",
    "\n",
    "# Libera los recursos\n",
    "video_input.release()\n",
    "video_output.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
